{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Persistent FP8 Matmul\nThis script demonstrates persistent kernel implementations of matrix multiplication using Triton.\nIt includes various matmul methods, such as naive, persistent, and TMA (Tensor Memory Accelerator) based approaches, and only supports GPUs with compute capability >= 9.0.\nTriton and CuBLAS implementations are benchmarked under different configurations and evaluated using the proton profiler.\nUsers can pass command-line arguments to specify matrix dimensions and iteration steps flexibly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import argparse\nimport time\n\nimport numpy as np\nimport torch\nimport triton\nimport triton.language as tl\nimport triton.profiler as proton\n\nfrom triton._C.libtriton import nvidia\n\nif torch.cuda.is_available():\n    cublas_workspace = torch.empty(32 * 1024 * 1024, device=\"cuda\", dtype=torch.uint8)\n    cublas = nvidia.cublas.CublasLt(cublas_workspace)\n\n\ndef _matmul_launch_metadata(grid, kernel, args):\n    ret = {}\n    M, N, K = args[\"M\"], args[\"N\"], args[\"K\"]\n    ret[\"name\"] = f\"{kernel.name} [M={M}, N={N}, K={K}]\"\n    ret[\"flops8\"] = 2. * M * N * K\n    ret[\"bytes\"] = M * K + N * K\n    return ret\n\n\n@triton.jit(launch_metadata=_matmul_launch_metadata)\ndef matmul_kernel(a_ptr, b_ptr, c_ptr,  #\n                  M, N, K,  #\n                  stride_am, stride_ak,  #\n                  stride_bk, stride_bn,  #\n                  stride_cm, stride_cn,  #\n                  BLOCK_SIZE_M: tl.constexpr,  #\n                  BLOCK_SIZE_N: tl.constexpr,  #\n                  BLOCK_SIZE_K: tl.constexpr,  #\n                  GROUP_SIZE_M: tl.constexpr,  #\n                  ):\n    pid = tl.program_id(axis=0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n    group_id = pid // num_pid_in_group\n    first_pid_m = group_id * GROUP_SIZE_M\n    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n    pid_m = first_pid_m + (pid % group_size_m)\n    pid_n = (pid % num_pid_in_group) // group_size_m\n\n    start_m = pid_m * BLOCK_SIZE_M\n    start_n = pid_n * BLOCK_SIZE_N\n\n    offs_am = tl.arange(0, BLOCK_SIZE_M)\n    offs_bn = tl.arange(0, BLOCK_SIZE_N)\n\n    offs_am = tl.where(offs_am < M - start_m, offs_am, 0)\n    offs_bn = tl.where(offs_bn < N - start_n, offs_bn, 0)\n\n    offs_am = tl.max_contiguous(tl.multiple_of(offs_am, BLOCK_SIZE_M), BLOCK_SIZE_M)\n    offs_bn = tl.max_contiguous(tl.multiple_of(offs_bn, BLOCK_SIZE_N), BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n        accumulator = tl.dot(a, b, accumulator)\n        a_ptrs += BLOCK_SIZE_K * stride_ak\n        b_ptrs += BLOCK_SIZE_K * stride_bk\n\n    c = accumulator.to(tl.float8e4nv)\n\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n    tl.store(c_ptrs, c, mask=c_mask)\n\n\ndef matmul(a, b):\n    BLOCK_SIZE_M = 128\n    BLOCK_SIZE_N = 256\n    BLOCK_SIZE_K = 128\n    GROUP_SIZE = 8\n    num_stages = 3\n    num_warps = 8\n\n    # Check constraints.\n    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n    M, K = a.shape\n    K, N = b.shape\n\n    c = torch.empty((M, N), device=a.device, dtype=torch.float8_e4m3fn)\n    # 1D launch kernel where each block gets its own program.\n    grid = lambda META: (triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"]), )\n    matmul_kernel[grid](\n        a, b, c,  #\n        M, N, K,  #\n        a.stride(0), a.stride(1),  #\n        b.stride(0), b.stride(1),  #\n        c.stride(0), c.stride(1),  #\n        BLOCK_SIZE_M=BLOCK_SIZE_M,  #\n        BLOCK_SIZE_N=BLOCK_SIZE_N,  #\n        BLOCK_SIZE_K=BLOCK_SIZE_K,  #\n        GROUP_SIZE_M=GROUP_SIZE,  #\n        num_stages=num_stages,  #\n        num_warps=num_warps,  #\n    )\n    return c\n\n\n@triton.jit(launch_metadata=_matmul_launch_metadata)\ndef matmul_kernel_persistent(a_ptr, b_ptr, c_ptr,  #\n                             M, N, K,  #\n                             stride_am, stride_ak,  #\n                             stride_bk, stride_bn,  #\n                             stride_cm, stride_cn,  #\n                             BLOCK_SIZE_M: tl.constexpr,  #\n                             BLOCK_SIZE_N: tl.constexpr,  #\n                             BLOCK_SIZE_K: tl.constexpr,  #\n                             GROUP_SIZE_M: tl.constexpr,  #\n                             NUM_SMS: tl.constexpr,  #\n                             ):\n    start_pid = tl.program_id(axis=0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)\n    num_tiles = num_pid_m * num_pid_n\n\n    tiles_per_SM = num_tiles // NUM_SMS\n    if start_pid < num_tiles % NUM_SMS:\n        tiles_per_SM += 1\n\n    tile_id = start_pid - NUM_SMS\n    ki = -1\n\n    offs_k_for_mask = tl.arange(0, BLOCK_SIZE_K)\n\n    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n\n    pid_m = 0\n    pid_n = 0\n    offs_am = tl.arange(0, BLOCK_SIZE_M)\n    offs_bn = tl.arange(0, BLOCK_SIZE_N)\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    for _ in range(0, k_tiles * tiles_per_SM):\n        ki = tl.where(ki == k_tiles - 1, 0, ki + 1)\n        if ki == 0:\n            tile_id += NUM_SMS\n            group_id = tile_id // num_pid_in_group\n            first_pid_m = group_id * GROUP_SIZE_M\n            group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n            pid_m = first_pid_m + (tile_id % group_size_m)\n            pid_n = (tile_id % num_pid_in_group) // group_size_m\n\n            start_m = pid_m * BLOCK_SIZE_M\n            start_n = pid_n * BLOCK_SIZE_N\n            offs_am = tl.arange(0, BLOCK_SIZE_M)\n            offs_bn = tl.arange(0, BLOCK_SIZE_N)\n            offs_am = tl.where(offs_am < M - start_m, offs_am, 0)\n            offs_bn = tl.where(offs_bn < N - start_n, offs_bn, 0)\n            offs_am = tl.max_contiguous(tl.multiple_of(offs_am, BLOCK_SIZE_M), BLOCK_SIZE_M)\n            offs_bn = tl.max_contiguous(tl.multiple_of(offs_bn, BLOCK_SIZE_N), BLOCK_SIZE_N)\n        offs_k = ki * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n        b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n\n        a = tl.load(a_ptrs, mask=offs_k_for_mask[None, :] < K - ki * BLOCK_SIZE_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k_for_mask[:, None] < K - ki * BLOCK_SIZE_K, other=0.0)\n        accumulator = tl.dot(a, b, accumulator)\n\n        if ki == k_tiles - 1:\n            offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n            offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n            c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n            c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n            c = accumulator.to(tl.float8e4nv)\n            tl.store(c_ptrs, c, mask=c_mask)\n            accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n\ndef matmul_persistent(a, b):\n    BLOCK_SIZE_M = 128\n    BLOCK_SIZE_N = 256\n    BLOCK_SIZE_K = 128\n    GROUP_SIZE = 8\n    num_stages = 3\n    num_warps = 8\n\n    # Check constraints.\n    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n\n    NUM_SMS = torch.cuda.get_device_properties(\"cuda\").multi_processor_count\n    M, K = a.shape\n    K, N = b.shape\n    # Allocates output.\n    c = torch.empty((M, N), device=a.device, dtype=a.dtype)\n    # 1D launch kernel where each block gets its own program.\n    grid = lambda META: (min(NUM_SMS, triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"])), )\n    matmul_kernel_persistent[grid](\n        a, b, c,  #\n        M, N, K,  #\n        a.stride(0), a.stride(1),  #\n        b.stride(0), b.stride(1),  #\n        c.stride(0), c.stride(1),  #\n        BLOCK_SIZE_M=BLOCK_SIZE_M,  #\n        BLOCK_SIZE_N=BLOCK_SIZE_N,  #\n        BLOCK_SIZE_K=BLOCK_SIZE_K,  #\n        GROUP_SIZE_M=GROUP_SIZE,  #\n        NUM_SMS=NUM_SMS,  #\n        num_stages=num_stages,  #\n        num_warps=num_warps,  #\n    )\n    return c\n\n\n@triton.jit(launch_metadata=_matmul_launch_metadata)\ndef matmul_kernel_tma_persistent(a_desc_ptr, b_desc_ptr, c_desc_ptr,  #\n                                 M, N, K,  #\n                                 BLOCK_SIZE_M: tl.constexpr,  #\n                                 BLOCK_SIZE_N: tl.constexpr,  #\n                                 BLOCK_SIZE_K: tl.constexpr,  #\n                                 GROUP_SIZE_M: tl.constexpr,  #\n                                 NUM_SMS: tl.constexpr):  #\n    start_pid = tl.program_id(axis=0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)\n    num_tiles = num_pid_m * num_pid_n\n\n    tiles_per_SM = num_tiles // NUM_SMS\n    if start_pid < num_tiles % NUM_SMS:\n        tiles_per_SM += 1\n\n    tile_id = start_pid - NUM_SMS\n    ki = -1\n\n    pid_m = 0\n    pid_n = 0\n    offs_am = 0\n    offs_bn = 0\n\n    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    for _ in range(0, k_tiles * tiles_per_SM):\n        ki = tl.where(ki == k_tiles - 1, 0, ki + 1)\n        if ki == 0:\n            tile_id += NUM_SMS\n            group_id = tile_id // num_pid_in_group\n            first_pid_m = group_id * GROUP_SIZE_M\n            group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n            pid_m = first_pid_m + (tile_id % group_size_m)\n            pid_n = (tile_id % num_pid_in_group) // group_size_m\n\n            offs_am = pid_m * BLOCK_SIZE_M\n            offs_bn = pid_n * BLOCK_SIZE_N\n\n            offs_am = tl.multiple_of(offs_am, BLOCK_SIZE_M)\n            offs_bn = tl.multiple_of(offs_bn, BLOCK_SIZE_N)\n\n        offs_k = ki * BLOCK_SIZE_K\n\n        a = tl._experimental_descriptor_load(a_desc_ptr, [offs_am, offs_k], [BLOCK_SIZE_M, BLOCK_SIZE_K], tl.float8e4nv)\n        b = tl._experimental_descriptor_load(b_desc_ptr, [offs_bn, offs_k], [BLOCK_SIZE_N, BLOCK_SIZE_K], tl.float8e4nv)\n        accumulator = tl.dot(a, b.T, accumulator)\n\n        if ki == k_tiles - 1:\n            c = accumulator.to(tl.float8e4nv)\n\n            tl._experimental_descriptor_store(c_desc_ptr, c, [offs_am, offs_bn])\n            accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n\ndef matmul_tma_persistent(a, b):\n    BLOCK_SIZE_M = 128\n    BLOCK_SIZE_N = 256\n    BLOCK_SIZE_K = 128\n    GROUP_SIZE = 8\n    num_stages = 3\n    num_warps = 8\n\n    # Check constraints.\n    assert a.shape[1] == b.shape[1], \"Incompatible dimensions\"  # b is transposed\n\n    M, K = a.shape\n    N, K = b.shape\n\n    c = torch.zeros((M, N), device=a.device, dtype=torch.float8_e4m3fn)\n\n    TMA_SIZE = 128\n\n    desc_a = np.empty(TMA_SIZE, dtype=np.int8)\n    desc_b = np.empty(TMA_SIZE, dtype=np.int8)\n    desc_c = np.empty(TMA_SIZE, dtype=np.int8)\n    triton.runtime.driver.active.utils.fill_2d_tma_descriptor(a.data_ptr(), M, K, BLOCK_SIZE_M, BLOCK_SIZE_K,\n                                                              a.element_size(), desc_a)\n    triton.runtime.driver.active.utils.fill_2d_tma_descriptor(b.data_ptr(), N, K, BLOCK_SIZE_N, BLOCK_SIZE_K,\n                                                              b.element_size(), desc_b)\n    triton.runtime.driver.active.utils.fill_2d_tma_descriptor(c.data_ptr(), M, N, BLOCK_SIZE_M, BLOCK_SIZE_N,\n                                                              c.element_size(), desc_c)\n\n    desc_a = torch.tensor(desc_a, device=\"cuda\")\n    desc_b = torch.tensor(desc_b, device=\"cuda\")\n    desc_c = torch.tensor(desc_c, device=\"cuda\")\n\n    NUM_SMS = torch.cuda.get_device_properties(\"cuda\").multi_processor_count\n\n    grid = lambda META: (min(NUM_SMS, triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"])), )\n    matmul_kernel_tma_persistent[grid](\n        desc_a, desc_b, desc_c,  #\n        M, N, K,  #\n        BLOCK_SIZE_M=BLOCK_SIZE_M,  #\n        BLOCK_SIZE_N=BLOCK_SIZE_N,  #\n        BLOCK_SIZE_K=BLOCK_SIZE_K,  #\n        GROUP_SIZE_M=GROUP_SIZE,  #\n        NUM_SMS=NUM_SMS,  #\n        num_stages=num_stages,  #\n        num_warps=num_warps,  #\n    )\n    return c\n\n\ndef cublas_matmul(a, b):\n    # Check constraints.\n    assert a.shape[1] == b.shape[1], \"Incompatible dimensions\"  # b is transposed\n\n    M, K = a.shape\n    N, K = b.shape\n\n    c = torch.empty((M, N), device=a.device, dtype=torch.float8_e4m3fn)\n\n    with proton.scope(f\"cublas M={M}, N={N}, K={K}\", {\"bytes\": M * K + N * K, \"flops8\": 2. * M * N * K}):\n        cublas.fp8_matmul(a, b, c)\n    return c\n\n\ndef bench(K, reps=10):\n    M = 8192\n    N = 8192\n    a = torch.randn((M, K), device=\"cuda\", dtype=torch.float16).to(torch.float8_e4m3fn)\n    b = torch.randn((K, N), device=\"cuda\", dtype=torch.float16).to(torch.float8_e4m3fn)\n\n    b = b.T.contiguous()\n\n    proton.activate(0)\n\n    for _ in range(reps):\n        cublas_matmul(a, b)\n        time.sleep(0.01)\n    for _ in range(reps):\n        matmul(a, b.T)\n        time.sleep(0.01)\n    for _ in range(reps):\n        matmul_persistent(a, b.T)\n        time.sleep(0.01)\n    for _ in range(reps):\n        matmul_tma_persistent(a, b)\n        time.sleep(0.01)\n\n    proton.deactivate(0)\n\n\ndef validate(M, N, K):\n    a = torch.randn((M, K), device=\"cuda\", dtype=torch.float16).to(torch.float8_e4m3fn)\n    b = torch.randn((K, N), device=\"cuda\", dtype=torch.float16).to(torch.float8_e4m3fn)\n    b = b.T.contiguous()\n    cublas_result = cublas_matmul(a, b)\n    naive_result = matmul(a, b.T)\n    persistent_result = matmul_persistent(a, b.T)\n    tma_persistent_result = matmul_tma_persistent(a, b)\n\n    naive_vs_cublas = \"\u2705\" if torch.allclose(naive_result.to(torch.float16), cublas_result.to(torch.float16),\n                                            atol=1.0) else \"\u274c\"\n    naive_vs_persistent = \"\u2705\" if torch.allclose(naive_result.to(torch.float16), persistent_result.to(torch.float16),\n                                                atol=1.0) else \"\u274c\"\n    naive_vs_tma_persistent = \"\u2705\" if torch.allclose(cublas_result.to(torch.float16),\n                                                    tma_persistent_result.to(torch.float16), atol=1.0) else \"\u274c\"\n    print(\n        f\"M={M}, N={N}, K={K} verification naive vs: cublas {naive_vs_cublas}, persistent {naive_vs_persistent}, TMA persistent {naive_vs_tma_persistent}\"\n    )\n\n\nif __name__ == \"__main__\":\n    if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 9:\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\"-K\", type=int, required=False)\n        parser.add_argument(\"--K_range\", type=int, nargs=2)\n        parser.add_argument(\"--K_step\", type=int, default=512)\n        args = parser.parse_args()\n\n        if args.K:\n            args.K_range = [args.K, args.K]\n            args.K_step = 1  # doesn't matter as long as it's not 0\n\n        torch.manual_seed(0)\n\n        validate(32, 32, 32)\n        validate(8192, 8192, 512)\n\n        proton.start(\"matmul\", hook=\"triton\")\n        for K in range(args.K_range[0], args.K_range[1] + 1, args.K_step):\n            bench(K)\n        proton.finalize()\n    else:\n        print(\"This tutorial fp8_matmul is only supported on CUDA with cc >= 90\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}